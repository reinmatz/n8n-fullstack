{
  "name": "02_Chat_Retrieval",
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "chat",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "webhook-chat",
      "name": "Webhook Chat",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1.1,
      "position": [250, 400],
      "webhookId": "chat-query",
      "credentials": {
        "httpBasicAuth": {
          "id": "1",
          "name": "n8n BasicAuth"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Extract and validate query from request body\nconst items = $input.all();\nconst results = [];\n\nfor (const item of items) {\n  const body = item.json.body || item.json;\n  const query = body.query || '';\n  const filters = body.filters || {};\n  const sessionId = body.session_id || null;\n  \n  if (!query || query.trim().length === 0) {\n    throw new Error('Query is required');\n  }\n  \n  if (query.length > 1000) {\n    throw new Error('Query too long (max 1000 characters)');\n  }\n  \n  results.push({\n    json: {\n      query: query.trim(),\n      filters,\n      sessionId: sessionId || require('crypto').randomUUID(),\n      timestamp: new Date().toISOString()\n    }\n  });\n}\n\nreturn results;"
      },
      "id": "extract-query",
      "name": "Extract Query",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [450, 400]
    },
    {
      "parameters": {
        "jsCode": "// Query Expansion: Add synonyms and related terms for better retrieval\nconst items = $input.all();\nconst results = [];\n\n// Simple German synonym dictionary for common terms\nconst SYNONYMS = {\n  'dokument': ['datei', 'file', 'unterlage'],\n  'suche': ['finde', 'ermittle', 'zeige'],\n  'information': ['info', 'daten', 'angaben'],\n  'liste': ['auflistung', 'übersicht', 'verzeichnis'],\n  'beispiel': ['sample', 'muster', 'vorlage']\n};\n\nfor (const item of items) {\n  const originalQuery = item.json.query;\n  const expandedTerms = [originalQuery];\n  \n  // Extract keywords (simple word tokenization)\n  const words = originalQuery.toLowerCase().split(/\\s+/);\n  \n  for (const word of words) {\n    if (SYNONYMS[word]) {\n      expandedTerms.push(...SYNONYMS[word]);\n    }\n  }\n  \n  // Create expanded query (original + synonyms)\n  const expandedQuery = [...new Set(expandedTerms)].join(' ');\n  \n  results.push({\n    json: {\n      ...item.json,\n      originalQuery,\n      expandedQuery,\n      expansionApplied: expandedTerms.length > 1\n    }\n  });\n}\n\nreturn results;"
      },
      "id": "query-expansion",
      "name": "Query Expansion",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [650, 400]
    },
    {
      "parameters": {
        "url": "http://ollama:11434/api/embeddings",
        "method": "POST",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ JSON.stringify({\n  model: 'bge-m3',\n  prompt: $json.expandedQuery\n}) }}",
        "options": {
          "timeout": 15000
        }
      },
      "id": "query-embedding",
      "name": "Query Embedding",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.1,
      "position": [850, 400]
    },
    {
      "parameters": {
        "url": "http://qdrant:6333/collections/rag_documents/points/search",
        "method": "POST",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ JSON.stringify({\n  vector: $json.embedding,\n  limit: 20,\n  with_payload: true,\n  with_vector: false,\n  filter: Object.keys($('Extract Query').item.json.filters).length > 0 ? {\n    must: Object.entries($('Extract Query').item.json.filters).map(([key, value]) => ({\n      key,\n      match: { value }\n    }))\n  } : undefined\n}) }}",
        "options": {
          "timeout": 15000
        }
      },
      "id": "vector-search",
      "name": "Vector Search (Qdrant)",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.1,
      "position": [1050, 300]
    },
    {
      "parameters": {
        "url": "http://qdrant:6333/collections/rag_documents/points/query",
        "method": "POST",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ JSON.stringify({\n  query: {\n    text: $('Query Expansion').item.json.expandedQuery\n  },\n  using: 'content',\n  limit: 10,\n  with_payload: true\n}) }}",
        "options": {
          "timeout": 15000
        }
      },
      "id": "bm25-search",
      "name": "BM25 Search (Hybrid)",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.1,
      "position": [1050, 500]
    },
    {
      "parameters": {
        "jsCode": "// Merge Vector + BM25 results using Reciprocal Rank Fusion (RRF)\nconst vectorResults = $('Vector Search (Qdrant)').all();\nconst bm25Results = $('BM25 Search (Hybrid)').all();\n\nconst K = 60; // RRF constant\nconst scores = {};\n\n// Process vector search results\nif (vectorResults && vectorResults[0]?.json?.result) {\n  const results = vectorResults[0].json.result;\n  results.forEach((item, rank) => {\n    const id = item.id;\n    scores[id] = scores[id] || { payload: item.payload, score: 0, sources: [] };\n    scores[id].score += 1 / (K + rank + 1);\n    scores[id].sources.push('vector');\n  });\n}\n\n// Process BM25 results\nif (bm25Results && bm25Results[0]?.json?.result) {\n  const results = bm25Results[0].json.result;\n  results.forEach((item, rank) => {\n    const id = item.id;\n    scores[id] = scores[id] || { payload: item.payload, score: 0, sources: [] };\n    scores[id].score += 1 / (K + rank + 1);\n    scores[id].sources.push('bm25');\n  });\n}\n\n// Sort by RRF score and deduplicate\nconst merged = Object.entries(scores)\n  .map(([id, data]) => ({\n    id,\n    ...data.payload,\n    rrf_score: data.score,\n    retrieval_sources: data.sources\n  }))\n  .sort((a, b) => b.rrf_score - a.rrf_score)\n  .slice(0, 20); // Top 20 for reranking\n\nreturn merged.map(item => ({ json: item }));"
      },
      "id": "merge-rrf",
      "name": "Merge Results (RRF)",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1250, 400]
    },
    {
      "parameters": {
        "jsCode": "// Simple reranking using cross-encoder scoring (simulated via Ollama)\n// In production, use a dedicated reranker model like bge-reranker-v2-m3\nconst items = $input.all();\nconst query = $('Query Expansion').first().json.originalQuery;\nconst results = [];\n\n// For now, use RRF score + content length heuristic\n// TODO: Replace with actual cross-encoder model when available\nfor (const item of items) {\n  const content = item.json.content || '';\n  const queryTerms = query.toLowerCase().split(/\\s+/);\n  const contentLower = content.toLowerCase();\n  \n  // Simple relevance score: RRF + term overlap\n  let termOverlap = 0;\n  queryTerms.forEach(term => {\n    if (contentLower.includes(term)) termOverlap++;\n  });\n  \n  const rerankScore = item.json.rrf_score * 0.7 + (termOverlap / queryTerms.length) * 0.3;\n  \n  results.push({\n    json: {\n      ...item.json,\n      rerank_score: rerankScore\n    }\n  });\n}\n\n// Sort by rerank score and take top 5\nconst topResults = results\n  .sort((a, b) => b.json.rerank_score - a.json.rerank_score)\n  .slice(0, 5);\n\nreturn topResults;"
      },
      "id": "reranking",
      "name": "Reranking (Top 5)",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1450, 400]
    },
    {
      "parameters": {
        "jsCode": "// Build context with citation markers\nconst items = $input.all();\nconst query = $('Query Expansion').first().json.originalQuery;\n\nlet context = '';\nconst sources = [];\n\nitems.forEach((item, index) => {\n  const citationNum = index + 1;\n  const content = item.json.content || '';\n  const filename = item.json.filename || 'Unknown';\n  const pageNum = item.json.page_number;\n  const section = item.json.section || 'Untitled';\n  \n  // Add citation marker\n  context += `[${citationNum}] (Quelle: ${filename}${pageNum ? `, Seite ${pageNum}` : ''}, Abschnitt: ${section})\\n${content}\\n\\n`;\n  \n  // Track source for response\n  sources.push({\n    citation: citationNum,\n    filename,\n    page_number: pageNum,\n    section,\n    snippet: content.substring(0, 150) + '...'\n  });\n});\n\nconst systemPrompt = `Du bist ein hilfreicher Assistent, der Fragen basierend auf bereitgestellten Dokumenten beantwortet. \n\nWICHTIG:\n- Beantworte die Frage NUR basierend auf den bereitgestellten Kontextinformationen.\n- Zitiere IMMER die Quellen mit den Nummern [1], [2], etc.\n- Wenn die Antwort nicht in den Dokumenten steht, sage das klar.\n- Sei präzise und faktentreu.\n- Antworte auf Deutsch.`;\n\nconst userPrompt = `Kontext:\\n${context}\\n\\nFrage: ${query}\\n\\nBitte beantworte die Frage basierend auf den obigen Informationen und gib die Quellennummern an.`;\n\nreturn [{\n  json: {\n    systemPrompt,\n    userPrompt,\n    sources,\n    contextLength: context.length,\n    sourceCount: sources.length\n  }\n}];"
      },
      "id": "context-building",
      "name": "Context Building",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1650, 400]
    },
    {
      "parameters": {
        "url": "http://ollama:11434/api/generate",
        "method": "POST",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ JSON.stringify({\n  model: 'qwen2.5:3b-instruct',\n  prompt: $json.userPrompt,\n  system: $json.systemPrompt,\n  stream: false,\n  options: {\n    temperature: 0.2,\n    top_p: 0.9,\n    max_tokens: 512\n  }\n}) }}",
        "options": {
          "timeout": 60000
        }
      },
      "id": "llm-generation",
      "name": "LLM Generation (Ollama)",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.1,
      "position": [1850, 400]
    },
    {
      "parameters": {
        "url": "http://postgres:5432",
        "operation": "executeQuery",
        "query": "=INSERT INTO messages (session_id, role, content, citations, metadata, model_used)\nVALUES (\n  '{{ $('Extract Query').item.json.sessionId }}',\n  'user',\n  '{{ $('Query Expansion').item.json.originalQuery }}',\n  '[]'::jsonb,\n  '{}'::jsonb,\n  'user-input'\n);\n\nINSERT INTO messages (session_id, role, content, citations, metadata, model_used)\nVALUES (\n  '{{ $('Extract Query').item.json.sessionId }}',\n  'assistant',\n  '{{ $json.response }}',\n  '{{ JSON.stringify($('Context Building').item.json.sources) }}'::jsonb,\n  '{\"context_length\": {{ $('Context Building').item.json.contextLength }}, \"sources_count\": {{ $('Context Building').item.json.sourceCount }} }'::jsonb,\n  'qwen2.5:3b-instruct'\n);\n\nSELECT session_id FROM chat_sessions WHERE session_id = '{{ $('Extract Query').item.json.sessionId }}';",
        "options": {}
      },
      "id": "save-chat-history",
      "name": "Save Chat History (PostgreSQL)",
      "type": "n8n-nodes-base.postgres",
      "typeVersion": 2.4,
      "position": [2050, 400],
      "credentials": {
        "postgres": {
          "id": "2",
          "name": "PostgreSQL n8n"
        }
      }
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ JSON.stringify({\n  answer: $('LLM Generation (Ollama)').item.json.response,\n  sources: $('Context Building').item.json.sources,\n  session_id: $('Extract Query').item.json.sessionId,\n  metadata: {\n    query: $('Query Expansion').item.json.originalQuery,\n    expansion_applied: $('Query Expansion').item.json.expansionApplied,\n    retrieval_sources: 'vector+bm25',\n    reranked: true,\n    model: 'qwen2.5:3b-instruct',\n    context_length: $('Context Building').item.json.contextLength,\n    timestamp: new Date().toISOString()\n  }\n}) }}",
        "options": {}
      },
      "id": "response-chat",
      "name": "Response Chat",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [2250, 400]
    }
  ],
  "connections": {
    "Webhook Chat": {
      "main": [[{ "node": "Extract Query", "type": "main", "index": 0 }]]
    },
    "Extract Query": {
      "main": [[{ "node": "Query Expansion", "type": "main", "index": 0 }]]
    },
    "Query Expansion": {
      "main": [[{ "node": "Query Embedding", "type": "main", "index": 0 }]]
    },
    "Query Embedding": {
      "main": [
        [{ "node": "Vector Search (Qdrant)", "type": "main", "index": 0 }],
        [{ "node": "BM25 Search (Hybrid)", "type": "main", "index": 0 }]
      ]
    },
    "Vector Search (Qdrant)": {
      "main": [[{ "node": "Merge Results (RRF)", "type": "main", "index": 0 }]]
    },
    "BM25 Search (Hybrid)": {
      "main": [[{ "node": "Merge Results (RRF)", "type": "main", "index": 0 }]]
    },
    "Merge Results (RRF)": {
      "main": [[{ "node": "Reranking (Top 5)", "type": "main", "index": 0 }]]
    },
    "Reranking (Top 5)": {
      "main": [[{ "node": "Context Building", "type": "main", "index": 0 }]]
    },
    "Context Building": {
      "main": [[{ "node": "LLM Generation (Ollama)", "type": "main", "index": 0 }]]
    },
    "LLM Generation (Ollama)": {
      "main": [[{ "node": "Save Chat History (PostgreSQL)", "type": "main", "index": 0 }]]
    },
    "Save Chat History (PostgreSQL)": {
      "main": [[{ "node": "Response Chat", "type": "main", "index": 0 }]]
    }
  },
  "pinData": {},
  "settings": {
    "executionOrder": "v1"
  },
  "staticData": null,
  "tags": [],
  "triggerCount": 1,
  "updatedAt": "2025-11-09T13:00:00.000Z",
  "versionId": "1.0.0"
}
